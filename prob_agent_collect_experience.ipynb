{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wumpus World - Probabilistic Agent\n",
    "\n",
    "### Using the probabilistic agent to generate experience data (states, actions and rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two experience data sets had been generated (5,000 games each). Total number of moves is 152,926.**\n",
    "\n",
    "Belief state is encoded as a 3-D tensor using 13 feature planes (each plane is a grid_height x grid_width matrix). The state shape is (13, grid_height, grid_width). See the `ProbAgent.encode_belief_state()` function.\n",
    "\n",
    "- Plane 1 - location of the agent\n",
    "- Plane 2 - visited locations\n",
    "- Plane 3 - stench locations\n",
    "- Plane 4 - breeze locations\n",
    "- Planes 5-8 - orientation of the agent\n",
    "- Plane 9 - does the agent have gold?\n",
    "- Plane 10 - does the agent perceive a glitter?\n",
    "- Plane 11 - does the agent have an arrow?\n",
    "- Plane 12 - have the agent heard a scream?\n",
    "- Plane 13 - does the agent perceives a bump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "\n",
    "class Orientation(enum.Enum):\n",
    "    north = 1\n",
    "    south = 2\n",
    "    east = 3\n",
    "    west = 4\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def turn_left(self):\n",
    "        dict_turn_left = {\n",
    "            Orientation.north: Orientation.west, \n",
    "            Orientation.south: Orientation.east, \n",
    "            Orientation.east: Orientation.north, \n",
    "            Orientation.west: Orientation.south\n",
    "        }\n",
    "        new_orientation = dict_turn_left.get(self)\n",
    "        return new_orientation\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def turn_right(self):\n",
    "        dict_turn_right = {\n",
    "            Orientation.north: Orientation.east, \n",
    "            Orientation.south: Orientation.west, \n",
    "            Orientation.east: Orientation.south, \n",
    "            Orientation.west: Orientation.north\n",
    "        }\n",
    "        new_orientation = dict_turn_right.get(self)\n",
    "        return new_orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action():\n",
    "    def __init__(self, is_forward=False, is_turn_left=False, is_turn_right=False, \n",
    "                 is_shoot=False, is_grab=False, is_climb=False):\n",
    "        assert is_forward ^ is_turn_left ^ is_turn_right ^ is_shoot ^ is_grab ^ is_climb\n",
    "        self.is_forward = is_forward\n",
    "        self.is_turn_left = is_turn_left\n",
    "        self.is_turn_right = is_turn_right\n",
    "        self.is_shoot = is_shoot\n",
    "        self.is_grab = is_grab\n",
    "        self.is_climb = is_climb\n",
    "    \n",
    "    @classmethod\n",
    "    def forward(cls):\n",
    "        return Action(is_forward=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def turn_left(cls):\n",
    "        return Action(is_turn_left=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def turn_right(cls):\n",
    "        return Action(is_turn_right=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def shoot(cls):\n",
    "        return Action(is_shoot=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def grab(cls):\n",
    "        return Action(is_grab=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def climb(cls):\n",
    "        return Action(is_climb=True)\n",
    "    \n",
    "    def show(self):\n",
    "        if self.is_forward:\n",
    "            action_str = \"forward\"\n",
    "        elif self.is_turn_left:\n",
    "            action_str = \"turn_left\"\n",
    "        elif self.is_turn_right:\n",
    "            action_str = \"turn_right\"\n",
    "        elif self.is_shoot:\n",
    "            action_str = \"shoot\"\n",
    "        elif self.is_grab:\n",
    "            action_str = \"grab\"\n",
    "        else:\n",
    "            action_str = \"climb\"\n",
    "        return action_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "class Coords(namedtuple('Coords', 'x y')):\n",
    "    def adjacent_cells(self, grid_width, grid_height):\n",
    "        neighbors = []\n",
    "        if self.x > 0: # to left\n",
    "            neighbors.append(Coords(self.x - 1, self.y))\n",
    "        if self.x < (grid_width - 1): # to right\n",
    "            neighbors.append(Coords(self.x + 1, self.y))\n",
    "        if self.y > 0: # below\n",
    "            neighbors.append(Coords(self.x, self.y - 1))\n",
    "        if self.y < (grid_height - 1): # above\n",
    "            neighbors.append(Coords(self.x, self.y + 1))\n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Percept():\n",
    "    def __init__(self, stench, breeze, glitter, bump, scream, is_terminated, reward):\n",
    "        self.stench = stench\n",
    "        self.breeze = breeze\n",
    "        self.glitter = glitter\n",
    "        self.bump = bump\n",
    "        self.scream = scream\n",
    "        self.is_terminated = is_terminated\n",
    "        self.reward = reward\n",
    "    \n",
    "    def show(self):\n",
    "        print(\"stench: {}, breeze: {}, glitter: {}, bump: {}, scream: {}, is_terminated: {}, reward: {}\"\n",
    "              .format(self.stench, self.breeze, self.glitter, self.bump, self.scream, self.is_terminated, self.reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class AgentState():\n",
    "    def __init__(self, location=Coords(0, 0), orientation=Orientation.east, has_gold=False, has_arrow=True, is_alive=True):\n",
    "        self.location = location\n",
    "        self.orientation = orientation\n",
    "        self.has_gold = has_gold\n",
    "        self.has_arrow = has_arrow\n",
    "        self.is_alive = is_alive\n",
    "    \n",
    "    def turn_left(self):\n",
    "        new_state = copy.deepcopy(self)\n",
    "        new_state.orientation = new_state.orientation.turn_left\n",
    "        return new_state\n",
    "    \n",
    "    def turn_right(self):\n",
    "        new_state = copy.deepcopy(self)\n",
    "        new_state.orientation = new_state.orientation.turn_right\n",
    "        return new_state\n",
    "    \n",
    "    def forward(self, grid_width, grid_height):\n",
    "        if self.orientation == Orientation.north:\n",
    "            new_loc = Coords(self.location.x, min(grid_height - 1, self.location.y + 1))\n",
    "        elif self.orientation == Orientation.south:\n",
    "            new_loc = Coords(self.location.x, max(0, self.location.y - 1))\n",
    "        elif self.orientation == Orientation.east:\n",
    "            new_loc = Coords(min(grid_width - 1, self.location.x + 1), self.location.y)\n",
    "        else:\n",
    "            new_loc = Coords(max(0, self.location.x - 1), self.location.y) # if Orientation.west\n",
    "        new_state = copy.deepcopy(self)\n",
    "        new_state.location = new_loc\n",
    "        return new_state\n",
    "    \n",
    "    def apply_move_action(self, action, grid_width, grid_height):\n",
    "        if action.is_forward:\n",
    "            return self.forward(grid_width, grid_height)\n",
    "        if action.is_turn_left:\n",
    "            return self.turn_left()\n",
    "        if action.is_turn_right:\n",
    "            return self.turn_right()\n",
    "        if action.is_shoot:\n",
    "            return self.use_arrow()\n",
    "        if action.is_climb:\n",
    "            return self\n",
    "    \n",
    "    def use_arrow(self):\n",
    "        new_state = copy.deepcopy(self)\n",
    "        new_state.has_arrow = False\n",
    "        return new_state\n",
    "    \n",
    "    def show(self):\n",
    "        print(\"location: {}, orientation: {}, has_gold: {}, has_arrow: {}, is_alive: {}\"\n",
    "              .format(self.location, self.orientation, self.has_gold, self.has_arrow, self.is_alive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions to create the list of all locations on the board and to generate the locations of gold, wumpus and pits**\n",
    "\n",
    "The locations of the gold and the Wumpus are chosen randomly, with a uniform distribution, from the squares other than the start square.\n",
    "\n",
    "Each square other than the start can be a pit, with probability = pit_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Create a list with all locations\n",
    "def list_all_locations(grid_width, grid_height):\n",
    "    all_cells = []\n",
    "    for x in range(grid_width):\n",
    "        for y in range(grid_height):\n",
    "            all_cells.append(Coords(x, y))\n",
    "    return all_cells\n",
    "\n",
    "\n",
    "# Create locations for gold and wumpus\n",
    "def random_location_except_origin(grid_width, grid_height):\n",
    "    locations = list_all_locations(grid_width, grid_height)\n",
    "    locations.remove(Coords(0, 0))\n",
    "    return random.choice(locations)\n",
    "\n",
    "\n",
    "# Create pit locations\n",
    "def create_pit_locations(grid_width, grid_height, pit_prob):\n",
    "    locations = list_all_locations(grid_width, grid_height)\n",
    "    locations.remove(Coords(0, 0))\n",
    "    pit_locations = [loc for loc in locations if random.random() < pit_prob]\n",
    "    return pit_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class Environment():\n",
    "    def __init__(self, grid_width, grid_height, pit_prob, allow_climb_without_gold, agent, pit_locations,\n",
    "                 terminated, wumpus_loc, wumpus_alive, gold_loc):\n",
    "        self.grid_width = grid_width\n",
    "        self.grid_height = grid_height\n",
    "        self.pit_prob = pit_prob\n",
    "        self.allow_climb_without_gold = allow_climb_without_gold\n",
    "        self.agent = agent\n",
    "        self.pit_locations = pit_locations\n",
    "        self.terminated = terminated\n",
    "        self.wumpus_loc = wumpus_loc\n",
    "        self.wumpus_alive = wumpus_alive\n",
    "        self.gold_loc = gold_loc\n",
    "    \n",
    "    def is_pit_at(self, coords):\n",
    "        return coords in self.pit_locations\n",
    "    \n",
    "    def is_wumpus_at(self, coords):\n",
    "        return coords == self.wumpus_loc\n",
    "    \n",
    "    def is_agent_at(self, coords):\n",
    "        return coords == self.agent.location\n",
    "    \n",
    "    def is_glitter(self):\n",
    "        return self.gold_loc == self.agent.location\n",
    "    \n",
    "    def is_gold_at(self, coords):\n",
    "        return coords == self.gold_loc\n",
    "    \n",
    "    def wumpus_in_line_of_fire(self):\n",
    "        if self.agent.orientation == Orientation.west:\n",
    "            return self.agent.location.x > self.wumpus_loc.x and self.agent.location.y == self.wumpus_loc.y\n",
    "        if self.agent.orientation == Orientation.east:\n",
    "            return self.agent.location.x < self.wumpus_loc.x and self.agent.location.y == self.wumpus_loc.y\n",
    "        if self.agent.orientation == Orientation.south:\n",
    "            return self.agent.location.x == self.wumpus_loc.x and self.agent.location.y > self.wumpus_loc.y\n",
    "        if self.agent.orientation == Orientation.north:\n",
    "            return self.agent.location.x == self.wumpus_loc.x and self.agent.location.y < self.wumpus_loc.y\n",
    "    \n",
    "    def kill_attempt_successful(self):\n",
    "        return self.agent.has_arrow and self.wumpus_alive and self.wumpus_in_line_of_fire()\n",
    "    \n",
    "    def is_pit_adjacent(self, coords):\n",
    "        for cell in coords.adjacent_cells(self.grid_width, self.grid_height):\n",
    "            if cell in self.pit_locations:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_wumpus_adjacent(self, coords):\n",
    "        for cell in coords.adjacent_cells(self.grid_width, self.grid_height):\n",
    "            if self.is_wumpus_at(cell):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_breeze(self):\n",
    "        return self.is_pit_adjacent(self.agent.location)\n",
    "    \n",
    "    def is_stench(self):\n",
    "        return self.is_wumpus_adjacent(self.agent.location) or self.is_wumpus_at(self.agent.location)\n",
    "    \n",
    "    def apply_action(self, action):\n",
    "        if self.terminated:\n",
    "            return (self, Percept(False, False, False, False, False, True, 0))\n",
    "        else:\n",
    "            if action.is_forward:\n",
    "                moved_agent = self.agent.forward(self.grid_width, self.grid_height)\n",
    "                death = (self.is_wumpus_at(moved_agent.location) and self.wumpus_alive) or self.is_pit_at(moved_agent.location)\n",
    "                new_agent = copy.deepcopy(moved_agent)\n",
    "                new_agent.is_alive = not death\n",
    "                new_gold_loc = new_agent.location if self.agent.has_gold else self.gold_loc\n",
    "                new_env = Environment(self.grid_width, self.grid_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      new_agent, self.pit_locations, death, self.wumpus_loc, self.wumpus_alive, new_gold_loc)\n",
    "                percept = Percept(new_env.is_stench(), new_env.is_breeze(), new_env.is_glitter(), \n",
    "                                  new_agent.location == self.agent.location, False, death, \n",
    "                                  -1 if new_agent.is_alive else -1001)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.is_turn_left:\n",
    "                new_env = Environment(self.grid_width, self.grid_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      self.agent.turn_left(), self.pit_locations, self.terminated, self.wumpus_loc, \n",
    "                                      self.wumpus_alive, self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False, False, -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.is_turn_right:\n",
    "                new_env = Environment(self.grid_width, self.grid_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      self.agent.turn_right(), self.pit_locations, self.terminated, self.wumpus_loc, \n",
    "                                      self.wumpus_alive, self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False, False, -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.is_grab:\n",
    "                new_agent = copy.deepcopy(self.agent)\n",
    "                new_agent.has_gold = self.is_glitter()\n",
    "                new_gold_loc = new_agent.location if new_agent.has_gold else self.gold_loc\n",
    "                new_env = Environment(self.grid_width, self.grid_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      new_agent, self.pit_locations, self.terminated, self.wumpus_loc, self.wumpus_alive, \n",
    "                                      new_gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False, False, -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.is_climb:\n",
    "                in_start_loc = self.agent.location == Coords(0, 0)\n",
    "                success = self.agent.has_gold and in_start_loc\n",
    "                is_terminated = success or (self.allow_climb_without_gold and in_start_loc)\n",
    "                new_env = Environment(self.grid_width, self.grid_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      self.agent, self.pit_locations, is_terminated, self.wumpus_loc, self.wumpus_alive, \n",
    "                                      self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, False, is_terminated, \n",
    "                                  999 if success else -1)\n",
    "                return (new_env, percept)\n",
    "            \n",
    "            if action.is_shoot:\n",
    "                had_arrow = self.agent.has_arrow\n",
    "                wumpus_killed = self.kill_attempt_successful()\n",
    "                new_agent = copy.deepcopy(self.agent)\n",
    "                new_agent.has_arrow = False\n",
    "                new_env = Environment(self.grid_width, self.grid_height, self.pit_prob, self.allow_climb_without_gold, \n",
    "                                      new_agent, self.pit_locations, self.terminated, self.wumpus_loc, \n",
    "                                      self.wumpus_alive and (not wumpus_killed), self.gold_loc)\n",
    "                percept = Percept(self.is_stench(), self.is_breeze(), self.is_glitter(), False, wumpus_killed, False, \n",
    "                                  -11 if had_arrow else -1)\n",
    "                return (new_env, percept)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def new_game(cls, grid_width, grid_height, pit_prob, allow_climb_without_gold):\n",
    "        new_pit_locations = create_pit_locations(grid_width, grid_height, pit_prob)\n",
    "        new_wumpus_loc = random_location_except_origin(grid_width, grid_height)\n",
    "        new_gold_loc = random_location_except_origin(grid_width, grid_height)\n",
    "        env = Environment(grid_width, grid_height, pit_prob, allow_climb_without_gold, \n",
    "                          AgentState(), new_pit_locations, False, new_wumpus_loc, True, new_gold_loc)\n",
    "        percept = Percept(env.is_stench(), env.is_breeze(), False, False, False, False, 0.0)\n",
    "        return (env, percept)\n",
    "    \n",
    "    \n",
    "    def visualize(self):\n",
    "        wumpus_symbol = \"W\" if self.wumpus_alive else \"w\"\n",
    "        all_rows = []\n",
    "        for y in range(self.grid_height - 1, -1, -1):\n",
    "            row = []\n",
    "            for x in range (self.grid_width):\n",
    "                agent = \"A\" if self.is_agent_at(Coords(x, y)) else \" \"\n",
    "                pit = \"P\" if self.is_pit_at(Coords(x, y)) else \" \"\n",
    "                gold = \"G\" if self.is_gold_at(Coords(x, y)) else \" \"\n",
    "                wumpus = wumpus_symbol if self.is_wumpus_at(Coords(x, y)) else \" \"\n",
    "                cell = agent + pit + gold + wumpus\n",
    "                row.append(cell)\n",
    "            row_str = \"|\".join(row)\n",
    "            all_rows.append(row_str)\n",
    "        final_str = \"\\n\".join(all_rows)\n",
    "        print(final_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions to encode and decode actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def encode_action_to_int(action):\n",
    "    if action.is_forward:\n",
    "        action_int = 0\n",
    "    elif action.is_turn_left:\n",
    "        action_int = 1\n",
    "    elif action.is_turn_right:\n",
    "        action_int = 2\n",
    "    elif action.is_shoot:\n",
    "        action_int = 3\n",
    "    elif action.is_grab:\n",
    "        action_int = 4\n",
    "    else: # climb\n",
    "        action_int = 5\n",
    "    return action_int\n",
    "\n",
    "\n",
    "def decode_action_index(index):\n",
    "    actions = [Action.forward(), Action.turn_left(), Action.turn_right(), Action.shoot(), Action.grab(), Action.climb()]\n",
    "    return actions[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `ExperienceBuffer` and `ExperienceCollector` classes: for handling experience data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# The ExperienceBuffer class to store the states, actions and rewards as NumPy arrays\n",
    "\n",
    "class ExperienceBuffer:\n",
    "    def __init__(self, states, actions, rewards):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "    \n",
    "    def serialize(self, h5file):\n",
    "        h5file.create_group('experience')\n",
    "        h5file['experience'].create_dataset('states', data=self.states)\n",
    "        h5file['experience'].create_dataset('actions', data=self.actions)\n",
    "        h5file['experience'].create_dataset('rewards', data=self.rewards)\n",
    "\n",
    "\n",
    "# Function to load the experience buffer from HDF5 file\n",
    "\n",
    "def load_experience(h5file):\n",
    "    return ExperienceBuffer(\n",
    "        states=np.array(h5file['experience']['states']),\n",
    "        actions=np.array(h5file['experience']['actions']),\n",
    "        rewards=np.array(h5file['experience']['rewards']))\n",
    "\n",
    "\n",
    "\n",
    "# The ExperienceCollector class to collect all the states, decisions and rewards (as Python lists)\n",
    "\n",
    "class ExperienceCollector:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "    \n",
    "    def record_state(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    def record_action(self, action):\n",
    "        self.actions.append(action)\n",
    "    \n",
    "    def record_reward(self, reward):\n",
    "        self.rewards.append(reward)\n",
    "    \n",
    "    def to_buffer(self):\n",
    "        return ExperienceBuffer(\n",
    "            states=np.array(self.states), \n",
    "            actions=np.array(self.actions), \n",
    "            rewards=np.array(self.rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def select_action(self, percept):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pomegranate import *\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "class ProbAgent(Agent):\n",
    "    \n",
    "    def __init__(self, grid_width, grid_height, pit_prob, agent_state, beeline_action_list, \n",
    "                 breeze_locations, stench_locations, visited_locations, heard_scream, \n",
    "                 inferred_pit_probs, inferred_wumpus_probs, perceives_glitter, perceives_bump):\n",
    "        self.grid_width = grid_width\n",
    "        self.grid_height = grid_height\n",
    "        self.pit_prob = pit_prob\n",
    "        self.agent_state = agent_state\n",
    "        self.beeline_action_list = beeline_action_list\n",
    "        self.breeze_locations = set(breeze_locations)\n",
    "        self.stench_locations = set(stench_locations)\n",
    "        self.visited_locations = set(visited_locations)\n",
    "        self.heard_scream = heard_scream\n",
    "        self.inferred_pit_probs = inferred_pit_probs\n",
    "        self.inferred_wumpus_probs = inferred_wumpus_probs\n",
    "        self.collector = None\n",
    "        self.perceives_glitter = perceives_glitter\n",
    "        self.perceives_bump = perceives_bump\n",
    "    \n",
    "    \n",
    "    \n",
    "    def set_collector(self, collector):\n",
    "        self.collector = collector\n",
    "    \n",
    "    \n",
    "    \n",
    "    def show(self):\n",
    "        self.agent_state.show()\n",
    "        print(\"visited_locations: {}\".format(self.visited_locations))\n",
    "        print(\"breeze_locations: {}\".format(self.breeze_locations))\n",
    "        print(\"stench_locations: {}\".format(self.stench_locations))\n",
    "        print(\"heard_scream: {}\".format(self.heard_scream))\n",
    "        print(\"perceives_glitter: {}\".format(self.perceives_glitter))\n",
    "        print(\"perceives_bump: {}\".format(self.perceives_bump))\n",
    "        print(\"inferred_pit_probs: {}\".format(self.inferred_pit_probs))\n",
    "        print(\"inferred_wumpus_probs: {}\".format(self.inferred_wumpus_probs))\n",
    "        print(\"beeline_action_list: {}\".format([action.show() for action in self.beeline_action_list]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def construct_beeline_plan(self, goal_node, safe_locations):\n",
    "        \n",
    "        # Create an undirected two-dimensional grid graph where each node is connected to its four nearest neighbors\n",
    "        G = nx.grid_2d_graph(self.grid_width, self.grid_height)\n",
    "        not_safe_locations = [node for node in G if node not in safe_locations]\n",
    "        G.remove_nodes_from(not_safe_locations) # keep only safe locations as nodes\n",
    "        \n",
    "        # Compute all shortest simple paths in the graph between source and target (every edge has weight/distance/cost 1)\n",
    "        shortest_paths = [p for p in nx.all_shortest_paths(G, source=self.agent_state.location, target=goal_node)]\n",
    "        \n",
    "        \n",
    "        # Functions for finding the new agent's orientation and required actions to move to the next point on the path\n",
    "        \n",
    "        def north(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation.turn_left, [Action.turn_left(), Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation.turn_right, [Action.turn_right(), Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation.turn_left.turn_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation, [Action.forward()])\n",
    "        \n",
    "        def south(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation.turn_right, [Action.turn_right(), Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation.turn_left, [Action.turn_left(), Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation, [Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation.turn_left.turn_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            \n",
    "        def east(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation.turn_left.turn_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation, [Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation.turn_right, [Action.turn_right(), Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation.turn_left, [Action.turn_left(), Action.forward()])\n",
    "        \n",
    "        def west(orientation, a, b):\n",
    "            if a.x > b.x: # move left\n",
    "                return (orientation, [Action.forward()])\n",
    "            if a.x < b.x: # move right\n",
    "                return (orientation.turn_left.turn_left, [Action.turn_left(), Action.turn_left(), Action.forward()])\n",
    "            if a.y > b.y: # move down\n",
    "                return (orientation.turn_left, [Action.turn_left(), Action.forward()])\n",
    "            if a.y < b.y: # move up\n",
    "                return (orientation.turn_right, [Action.turn_right(), Action.forward()])\n",
    "        \n",
    "        dict_orientation_to_actions = {\n",
    "            Orientation.north: north, \n",
    "            Orientation.south: south, \n",
    "            Orientation.east: east, \n",
    "            Orientation.west: west\n",
    "        }\n",
    "        \n",
    "        def determine_actions(orientation, a, b):\n",
    "            func = dict_orientation_to_actions.get(orientation)\n",
    "            return func(orientation, a, b)\n",
    "        \n",
    "        # Convert each shortest path into a plan (lists of actions)\n",
    "        plans_list = [] # list with plans for all shortest paths\n",
    "        for path in shortest_paths:\n",
    "            path_coords = [Coords(*node) for node in path] # convert all nodes to the Coords() type\n",
    "            orientation = self.agent_state.orientation\n",
    "            full_plan = []\n",
    "            for i in range(len(path_coords) - 1):\n",
    "                (orientation, actions) = determine_actions(orientation, path_coords[i], path_coords[i + 1])\n",
    "                full_plan.extend(actions)\n",
    "            plans_list.append(full_plan)\n",
    "        \n",
    "        # Find the number of turns for each plan (if more than one shortest path) and choose the plan with fewer turns\n",
    "        if len(plans_list) > 1:\n",
    "            plans_turn_counts = []\n",
    "            for plan in plans_list:\n",
    "                turn_count = 0\n",
    "                for action in plan:\n",
    "                    if action.is_turn_left or action.is_turn_right:\n",
    "                        turn_count += 1\n",
    "                plans_turn_counts.append(turn_count)\n",
    "            beeline_plan_index = plans_turn_counts.index(min(plans_turn_counts))\n",
    "            beeline_plan = plans_list[beeline_plan_index]\n",
    "        else:\n",
    "            beeline_plan = plans_list[0]\n",
    "        return beeline_plan\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Choose the first action from the beeline list of actions, update the agent_state and beeline_action_list\n",
    "    \n",
    "    def beeline(self, beeline_plan):\n",
    "        beeline_action = beeline_plan[0]\n",
    "        new_agent = copy.deepcopy(self)\n",
    "        new_agent.agent_state = new_agent.agent_state.apply_move_action(beeline_action, self.grid_width, self.grid_height)\n",
    "        new_agent.beeline_action_list = beeline_plan[1:]\n",
    "        return (new_agent, beeline_action)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Build a probabilistic model for wumpus and stench locations\n",
    "    \n",
    "    def create_model_wumpus(self):\n",
    "        \n",
    "        # List of all locations\n",
    "        all_cells = list_all_locations(self.grid_width, self.grid_height)\n",
    "        \n",
    "        # Discrete distribution for wumpus\n",
    "        wumpus_initial_probs = {}\n",
    "        for cell in all_cells:\n",
    "            if cell.x == 0 and cell.y == 0:\n",
    "                wumpus_initial_probs[cell] = 0.0\n",
    "            else:\n",
    "                wumpus_initial_probs[cell] = 1.0 / (self.grid_width * self.grid_height - 1)\n",
    "        wumpus_location_dist = DiscreteDistribution(wumpus_initial_probs)\n",
    "        \n",
    "        # Dictionary with wumpus CPDs (a CPD for each cell - probability of wumpus being at this cell and not at other cells)\n",
    "        dict_wumpus_probs = {}\n",
    "        for cell in all_cells:\n",
    "            wumpus_probs = []\n",
    "            for cell_2 in all_cells:\n",
    "                if cell_2 != cell:\n",
    "                    wumpus_probs.append([cell_2, True, 0.0])\n",
    "                    wumpus_probs.append([cell_2, False, 1.0])\n",
    "                else:\n",
    "                    wumpus_probs.append([cell_2, True, 1.0])\n",
    "                    wumpus_probs.append([cell_2, False, 0.0])\n",
    "            dict_wumpus_probs[cell] = ConditionalProbabilityTable(wumpus_probs, [wumpus_location_dist])\n",
    "        \n",
    "        #  Dictionary with stench CPDs (a CPD for each cell - probability of stench at this cell)\n",
    "        dict_stench_probs = {}\n",
    "        dict_neighbors = {} # dict where keys and values are cells and their neighbors respectively\n",
    "        for cell in all_cells:\n",
    "            neighbors = cell.adjacent_cells(self.grid_width, self.grid_height)\n",
    "            dict_neighbors[cell] = neighbors\n",
    "            if len(neighbors) == 2:\n",
    "                dict_stench_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 1, 0.0],\n",
    "                                                                       [0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1.0]], [dict_wumpus_probs[neighbors[0]],\n",
    "                                                                                         dict_wumpus_probs[neighbors[1]]])\n",
    "            elif len(neighbors) == 3:\n",
    "                dict_stench_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1.0]], [dict_wumpus_probs[neighbors[0]],\n",
    "                                                                                            dict_wumpus_probs[neighbors[1]],\n",
    "                                                                                            dict_wumpus_probs[neighbors[2]]])\n",
    "            else: # four neighbors\n",
    "                dict_stench_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1, 1.0]], [dict_wumpus_probs[neighbors[0]],\n",
    "                                                                                               dict_wumpus_probs[neighbors[1]],\n",
    "                                                                                               dict_wumpus_probs[neighbors[2]],\n",
    "                                                                                               dict_wumpus_probs[neighbors[3]]])\n",
    "        # Create states\n",
    "        wumpus_state = State(wumpus_location_dist)\n",
    "        \n",
    "        wumpus_cpd_states = {}\n",
    "        for cell in all_cells:\n",
    "            wumpus_cpd_states[cell] = State(dict_wumpus_probs[cell])\n",
    "        \n",
    "        stench_cpd_states = {}\n",
    "        for cell in all_cells:\n",
    "            stench_cpd_states[cell] = State(dict_stench_probs[cell])\n",
    "        \n",
    "        # Model\n",
    "        model_wumpus = BayesianNetwork(\"model_wumpus_stenches\")\n",
    "        \n",
    "        # Add states\n",
    "        model_wumpus.add_state(wumpus_state)\n",
    "        for cell in all_cells:\n",
    "            model_wumpus.add_state(wumpus_cpd_states[cell])\n",
    "        for cell in all_cells:\n",
    "            model_wumpus.add_state(stench_cpd_states[cell])\n",
    "        \n",
    "        # Add edges\n",
    "        for cell in all_cells:\n",
    "            model_wumpus.add_edge(wumpus_state, wumpus_cpd_states[cell])\n",
    "        for cell in all_cells:\n",
    "            for n in dict_neighbors[cell]:\n",
    "                model_wumpus.add_edge(wumpus_cpd_states[n], stench_cpd_states[cell])\n",
    "        \n",
    "        model_wumpus.bake()\n",
    "        return model_wumpus\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Build a probabilistic model for pit and breeze locations\n",
    "    \n",
    "    def create_model_pits(self):\n",
    "        # All locations in the grid\n",
    "        all_cells = list_all_locations(self.grid_width, self.grid_height)\n",
    "        \n",
    "        # Dictionary with discrete distributions for pits (a discrete distribution for each cell)\n",
    "        dict_pit_probs = {}\n",
    "        for cell in all_cells:\n",
    "            if cell.x == 0 and cell.y == 0:\n",
    "                dict_pit_probs[cell] = DiscreteDistribution({True: 0.0, False: 1.0})\n",
    "            else:\n",
    "                dict_pit_probs[cell] = DiscreteDistribution({True: self.pit_prob, False: 1 - self.pit_prob})\n",
    "        \n",
    "        # Dictionary with breeze CPDs (a CPD for each cell - probability of breeze at this cell)\n",
    "        dict_breeze_probs = {}\n",
    "        dict_neighbors = {} # dict where keys and values are cells and their neighbors respectively\n",
    "        for cell in all_cells:\n",
    "            neighbors = cell.adjacent_cells(self.grid_width, self.grid_height)\n",
    "            dict_neighbors[cell] = neighbors\n",
    "            if len(neighbors) == 2:\n",
    "                dict_breeze_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 1, 0.0],\n",
    "                                                                       [0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1.0]], [dict_pit_probs[neighbors[0]],\n",
    "                                                                                         dict_pit_probs[neighbors[1]]])\n",
    "            elif len(neighbors) == 3:\n",
    "                dict_breeze_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1.0]], [dict_pit_probs[neighbors[0]],\n",
    "                                                                                            dict_pit_probs[neighbors[1]],\n",
    "                                                                                            dict_pit_probs[neighbors[2]]])\n",
    "            else: # four neighbors\n",
    "                dict_breeze_probs[cell] = ConditionalProbabilityTable([[0, 0, 0, 0, 0, 1.0],\n",
    "                                                                       [0, 0, 0, 0, 1, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [0, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [0, 1, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 0, 1, 1.0],\n",
    "                                                                       [1, 0, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 0, 1, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 0, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 0, 1, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 0, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 0, 1, 1.0],\n",
    "                                                                       [1, 1, 1, 1, 0, 0.0],\n",
    "                                                                       [1, 1, 1, 1, 1, 1.0]], [dict_pit_probs[neighbors[0]],\n",
    "                                                                                               dict_pit_probs[neighbors[1]],\n",
    "                                                                                               dict_pit_probs[neighbors[2]],\n",
    "                                                                                               dict_pit_probs[neighbors[3]]])\n",
    "        \n",
    "        # Create states\n",
    "        pit_states = {}\n",
    "        for cell in all_cells:\n",
    "            pit_states[cell] = State(dict_pit_probs[cell])\n",
    "        \n",
    "        breeze_cpd_states = {}\n",
    "        for cell in all_cells:\n",
    "            breeze_cpd_states[cell] = State(dict_breeze_probs[cell])\n",
    "        \n",
    "        # Model\n",
    "        model_pits = BayesianNetwork(\"model_pits_breezes\")\n",
    "        \n",
    "        # Add states\n",
    "        for cell in all_cells:\n",
    "            model_pits.add_state(pit_states[cell])\n",
    "        for cell in all_cells:\n",
    "            model_pits.add_state(breeze_cpd_states[cell])\n",
    "        \n",
    "        # Add edges\n",
    "        for cell in all_cells:\n",
    "            for n in dict_neighbors[cell]:\n",
    "                model_pits.add_edge(pit_states[n], breeze_cpd_states[cell])\n",
    "        \n",
    "        model_pits.bake()\n",
    "        return model_pits\n",
    "    \n",
    "    \n",
    "    \n",
    "    def select_action(self, percept):\n",
    "        \n",
    "        # List of all locations\n",
    "        all_cells = list_all_locations(self.grid_width, self.grid_height)\n",
    "        \n",
    "        # Dictionary where keys and values are cells and their neighbors respectively\n",
    "        dict_neighbors = {cell : cell.adjacent_cells(self.grid_width, self.grid_height) for cell in all_cells}\n",
    "        \n",
    "        # Update agent's variables\n",
    "        visiting_new_location = self.agent_state.location not in self.visited_locations\n",
    "        if visiting_new_location:\n",
    "            self.visited_locations.add(self.agent_state.location)\n",
    "        if percept.breeze:\n",
    "            self.breeze_locations.add(self.agent_state.location)\n",
    "        if percept.stench:\n",
    "            self.stench_locations.add(self.agent_state.location)\n",
    "        new_heard_scream = self.heard_scream or percept.scream\n",
    "        self.heard_scream = new_heard_scream\n",
    "        self.perceives_glitter = percept.glitter\n",
    "        self.perceives_bump = percept.bump\n",
    "        \n",
    "        board_tensor = self.encode_belief_state() # encode belief state\n",
    "        if self.collector is not None: # record the state if collecting experience\n",
    "            self.collector.record_state(state=board_tensor)\n",
    "        \n",
    "        \n",
    "        #self.show() # print the agent_state, beeline_action_list and other details before selecting the action\n",
    "        \n",
    "        \n",
    "        # Predict wumpus probabilities for each cell if visiting a new location or if just shot an arrow and killed the wumpus\n",
    "        \n",
    "        update_wumpus_probs = visiting_new_location or (not visiting_new_location and percept.scream)\n",
    "        if update_wumpus_probs:\n",
    "            if new_heard_scream: # if wumpus is not alive, all probabilities are 0\n",
    "                new_inferred_wumpus_probs = {cell : 0.0 for cell in all_cells}\n",
    "            else: # create a prob model and perform inference\n",
    "                model_wumpus = self.create_model_wumpus()\n",
    "                \n",
    "                # Observations of wumpus and stenches\n",
    "                observations_wumpus = [None]\n",
    "                for cell in all_cells:\n",
    "                    if cell in self.visited_locations:\n",
    "                        observations_wumpus.append(False)\n",
    "                    else:\n",
    "                        observations_wumpus.append(None)\n",
    "                for cell in all_cells:\n",
    "                    if cell in self.stench_locations:\n",
    "                        observations_wumpus.append(True)\n",
    "                    elif cell not in self.visited_locations:\n",
    "                        observations_wumpus.append(None)\n",
    "                    else: # a visited location but no stench was observed\n",
    "                        observations_wumpus.append(False)\n",
    "                \n",
    "                # Compute the probabilities of wumpus\n",
    "                predict_wumpus_probs = model_wumpus.predict_proba([observations_wumpus])\n",
    "                new_inferred_wumpus_probs = predict_wumpus_probs[0][0].parameters[0]\n",
    "            self.inferred_wumpus_probs = new_inferred_wumpus_probs # update agent's inferred_wumpus_probs\n",
    "        else:\n",
    "            new_inferred_wumpus_probs = self.inferred_wumpus_probs\n",
    "        \n",
    "        \n",
    "        # Predict probabilities of there being a pit at each cell\n",
    "        # Create a prob model and perform inference if visiting a new location\n",
    "        \n",
    "        update_pit_probs = visiting_new_location\n",
    "        if update_pit_probs:\n",
    "            model_pits = self.create_model_pits()\n",
    "            \n",
    "            # Observations of pits and breezes\n",
    "            observations_pits = []\n",
    "            for cell in all_cells:\n",
    "                if cell in self.visited_locations:\n",
    "                    observations_pits.append(False)\n",
    "                else:\n",
    "                    observations_pits.append(None)\n",
    "            for cell in all_cells:\n",
    "                if cell in self.breeze_locations:\n",
    "                    observations_pits.append(True)\n",
    "                elif cell not in self.visited_locations:\n",
    "                    observations_pits.append(None)\n",
    "                else: # a visited location but no breeze was observed\n",
    "                    observations_pits.append(False)\n",
    "            \n",
    "            # Compute the new pit probabilities\n",
    "            predict_pit_probs = model_pits.predict_proba([observations_pits])\n",
    "            new_inferred_pit_probs = {}\n",
    "            for i, cell in enumerate(all_cells):\n",
    "                if isinstance(predict_pit_probs[0][i], Distribution):\n",
    "                    new_inferred_pit_probs[cell] = predict_pit_probs[0][i].parameters[0][True]\n",
    "                else: # there was observation of False at this cell\n",
    "                    new_inferred_pit_probs[cell] = 0.0\n",
    "            self.inferred_pit_probs = new_inferred_pit_probs # update agent's inferred_pit_probs\n",
    "        else:\n",
    "            new_inferred_pit_probs = self.inferred_pit_probs\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Find safe locations where probabilities of wumpus and pits are lower than the tolerance value\n",
    "        \n",
    "        def safe_locations_list(tolerance, locations_list, pit_probs, wumpus_probs):\n",
    "            safe_locations = [loc for loc in locations_list if (pit_probs[loc] < tolerance and wumpus_probs[loc] < tolerance)]\n",
    "            return safe_locations\n",
    "        \n",
    "        \n",
    "        # Safe locations for beeline home or to reach a new location\n",
    "        safe_locations_beeline = safe_locations_list(0.01, all_cells, new_inferred_pit_probs, new_inferred_wumpus_probs)\n",
    "        \n",
    "        # Safe locations to explore the grid\n",
    "        safe_locations_search = safe_locations_list(0.4, all_cells, new_inferred_pit_probs, new_inferred_wumpus_probs)\n",
    "        \n",
    "        #print(\"safe_locations(tol=0.01):\", safe_locations_beeline)\n",
    "        #print(\"safe_locations(tol=0.4):\", safe_locations_search)\n",
    "        \n",
    "        # Safe locations adjacent to the agent's location (tolerance=0.4)\n",
    "        adjacent_safe_locations = [loc for loc in self.agent_state.location.adjacent_cells(self.grid_width, self.grid_height) \\\n",
    "                                   if loc in safe_locations_search]\n",
    "        \n",
    "        # Locations where prob of wumpus is greater than 0.49 (agent can try to shoot an arrow there)\n",
    "        likely_wumpus_locations = [loc for loc in all_cells if new_inferred_wumpus_probs[loc] > 0.49]\n",
    "        # Locations where prob of wumpus is greater than 0.49 that can be reached via cells in safe_locations_beeline\n",
    "        reachable_likely_wumpus_locations = [loc for loc in likely_wumpus_locations \\\n",
    "                                             if any(neighbor in safe_locations_beeline for neighbor in dict_neighbors[loc])]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Select the next action\n",
    "        \n",
    "        if self.agent_state.has_gold: # agent with gold\n",
    "            if self.agent_state.location == Coords(0, 0): # climb with gold\n",
    "                return (self, Action.climb())\n",
    "            else: # beeline home with gold\n",
    "                beeline_home_plan = self.construct_beeline_plan(Coords(0, 0), safe_locations_beeline) \\\n",
    "                                    if self.beeline_action_list == [] else self.beeline_action_list\n",
    "                (new_agent, beeline_action) = self.beeline(beeline_home_plan)\n",
    "                return (new_agent, beeline_action)\n",
    "        else: # agent without gold\n",
    "            if percept.glitter: # grab the gold if glitter\n",
    "                new_agent = copy.deepcopy(self)\n",
    "                new_agent.agent_state.has_gold = True\n",
    "                return (new_agent, Action.grab())\n",
    "            elif self.beeline_action_list != []: # continue beelining to reach a new location / get home without gold / shoot\n",
    "                (new_agent, beeline_action) = self.beeline(self.beeline_action_list)\n",
    "                return (new_agent, beeline_action)\n",
    "            elif reachable_likely_wumpus_locations != [] and self.agent_state.has_arrow: # shoot an arrow at a likely wumpus loc\n",
    "                target_location = random.choice(reachable_likely_wumpus_locations)\n",
    "                locations_beeline_shoot = safe_locations_beeline.copy()\n",
    "                locations_beeline_shoot.append(target_location) # add the target location to locations for beelining\n",
    "                beeline_shoot_plan = self.construct_beeline_plan(target_location, locations_beeline_shoot)\n",
    "                del beeline_shoot_plan[-1] # remove the last action which is a move forward to a likely wumpus location\n",
    "                beeline_shoot_plan.append(Action.shoot()) # add the shoot action to the end of the list\n",
    "                (new_agent, beeline_action) = self.beeline(beeline_shoot_plan)\n",
    "                return (new_agent, beeline_action)\n",
    "            elif self.agent_state.location == Coords(0, 0) and adjacent_safe_locations == []: # unsafe to explore\n",
    "                if not percept.breeze and self.agent_state.has_arrow: # try to kill wumpus if low probability of pits around\n",
    "                    new_agent = copy.deepcopy(self)\n",
    "                    new_agent.agent_state = new_agent.agent_state.use_arrow()\n",
    "                    return (new_agent, Action.shoot())\n",
    "                else: # climb without gold\n",
    "                    return (self, Action.climb())\n",
    "            else: # search for gold\n",
    "                # Not visited locations adjacent to all previously visited locations\n",
    "                potential_visit_locations_set = {adj_loc for loc in self.visited_locations \\\n",
    "                                                for adj_loc in loc.adjacent_cells(self.grid_width, self.grid_height) \\\n",
    "                                                if adj_loc not in self.visited_locations}\n",
    "                potential_visit_locations_list = list(potential_visit_locations_set)\n",
    "                safe_potential_visit_locations = [loc for loc in potential_visit_locations_list if loc in safe_locations_search]\n",
    "                if safe_potential_visit_locations != []: # new safe locations exist; choose one and create a beeline plan to it\n",
    "                    search_coords_list = []\n",
    "                    search_wumpus_probs = []\n",
    "                    for loc in safe_potential_visit_locations:\n",
    "                        search_coords_list.append(loc)\n",
    "                        search_wumpus_probs.append(new_inferred_wumpus_probs[loc])\n",
    "                    next_location_index = search_wumpus_probs.index(min(search_wumpus_probs)) # find cell with min wumpus prob\n",
    "                    next_location = search_coords_list[next_location_index]\n",
    "                    locations_beeline_search = safe_locations_beeline.copy()\n",
    "                    locations_beeline_search.append(next_location) # add the chosen location to locations for beelining\n",
    "                    beeline_search_plan = self.construct_beeline_plan(next_location, locations_beeline_search)\n",
    "                    (new_agent, beeline_action) = self.beeline(beeline_search_plan)\n",
    "                    return (new_agent, beeline_action)\n",
    "                else: # no new safe locations to explore, beeline home without gold\n",
    "                    beeline_home_plan = self.construct_beeline_plan(Coords(0, 0), safe_locations_beeline)\n",
    "                    beeline_home_plan.append(Action.climb())\n",
    "                    (new_agent, beeline_action) = self.beeline(beeline_home_plan)\n",
    "                    return (new_agent, beeline_action)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def new_agent(cls, grid_width, grid_height, pit_prob):\n",
    "        return ProbAgent(grid_width, grid_height, pit_prob, AgentState(), [], set(), set(), set(), False, {}, {}, False, False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Encode belief state using 13 feature planes (each plane is a grid_height x grid_width matrix)\n",
    "    # The state shape is (13, grid_height, grid_width)\n",
    "    \n",
    "    def encode_belief_state(self):\n",
    "        board_tensor = np.zeros((13, self.grid_height, self.grid_width))\n",
    "        all_cells = list_all_locations(self.grid_width, self.grid_height)\n",
    "        \n",
    "        # The first plane has a 1 for agent's location and 0s for other locations\n",
    "        board_tensor[0][self.agent_state.location.y][self.agent_state.location.x] = 1\n",
    "        \n",
    "        for cell in all_cells:\n",
    "            if cell in self.visited_locations:\n",
    "                board_tensor[1][cell.y][cell.x] = 1 # 1s for visited locations\n",
    "            if cell in self.stench_locations:\n",
    "                board_tensor[2][cell.y][cell.x] = 1 # 1s for stench locations\n",
    "            if cell in self.breeze_locations:\n",
    "                board_tensor[3][cell.y][cell.x] = 1 # 1s for breeze locations\n",
    "        \n",
    "        if self.agent_state.orientation == Orientation.north: # a plane filled with 1s if Orientation.north\n",
    "            board_tensor[4] = 1\n",
    "        elif self.agent_state.orientation == Orientation.south: # a plane filled with 1s if Orientation.south\n",
    "            board_tensor[5] = 1\n",
    "        elif self.agent_state.orientation == Orientation.east: # a plane filled with 1s if Orientation.east\n",
    "            board_tensor[6] = 1\n",
    "        else: # a plane filled with 1s if Orientation.west\n",
    "            board_tensor[7] = 1\n",
    "        \n",
    "        if self.agent_state.has_gold: # a plane filled with 1s if agent has gold, and 0s otherwise\n",
    "            board_tensor[8] = 1\n",
    "        if self.perceives_glitter: # a plane filled with 1s if agent perceives glitter, and 0s otherwise\n",
    "            board_tensor[9] = 1\n",
    "        if self.agent_state.has_arrow: # a plane filled with 1s if agent has arrow, and 0s otherwise\n",
    "            board_tensor[10] = 1\n",
    "        if self.heard_scream: # a plane filled with 1s if wumpus is not alive, and 0s otherwise\n",
    "            board_tensor[11] = 1\n",
    "        if self.perceives_bump: # a plane filled with 1s if agent perceives bump, and 0s otherwise\n",
    "            board_tensor[12] = 1\n",
    "        \n",
    "        return board_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the experience data (5,000 games) and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "def main():\n",
    "    n_games = 5000\n",
    "    total_moves = 0\n",
    "    n_games_reward = 0\n",
    "    wins = 0\n",
    "    \n",
    "    collector = ExperienceCollector()\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        agent = ProbAgent.new_agent(4, 4, 0.2)\n",
    "        (env, percept) = Environment.new_game(4, 4, 0.2, True)\n",
    "        total_reward = 0\n",
    "        num_moves = 0\n",
    "        \n",
    "        while not percept.is_terminated:\n",
    "            agent.set_collector(collector)\n",
    "            (agent, next_action) = agent.select_action(percept)\n",
    "            next_action_int = encode_action_to_int(next_action) # encode action to int\n",
    "            collector.record_action(next_action_int) # add encoded action to collector\n",
    "            (env, percept) = env.apply_action(next_action)\n",
    "            collector.record_reward(percept.reward) # add reward to collector\n",
    "            total_reward += percept.reward\n",
    "            num_moves += 1\n",
    "        \n",
    "        #print(\"Game %d/%d\" % (i + 1, n_games))\n",
    "        #print(\"Total reward:\", total_reward)\n",
    "        #print(\"Moves per episode:\", num_moves)\n",
    "        \n",
    "        if agent.agent_state.has_gold:\n",
    "            wins += 1\n",
    "        n_games_reward += total_reward\n",
    "        total_moves += num_moves\n",
    "    \n",
    "    print(\"Number of games: \", n_games)\n",
    "    print(\"Total number of moves: \", total_moves)\n",
    "    print(\"n_games_reward:\", n_games_reward)\n",
    "    print(\"avg_reward_per_game: %.2f\" % (n_games_reward / n_games))\n",
    "    print(\"win_percent: %.2f\" % (wins / n_games))\n",
    "    \n",
    "    experience = collector.to_buffer() # convert the collector to a buffer\n",
    "    with h5py.File('prob_agent_experience_02', 'w') as exp_out: # save the buffer as a file\n",
    "        experience.serialize(exp_out)\n",
    "    \n",
    "    # Print the shapes of arrays in the buffer and the first state, action and reward\n",
    "    print(\"exp.states.shape: \", experience.states.shape)\n",
    "    print(\"exp.actions.shape: \", experience.actions.shape)\n",
    "    print(\"exp.rewards.shape: \", experience.rewards.shape)\n",
    "    print(\"exp.states[0]: \", experience.states[0])\n",
    "    print(\"exp.actions[0]: \", experience.actions[0])\n",
    "    print(\"exp.rewards[0]: \", experience.rewards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games:  5000\n",
      "Total number of moves:  76528\n",
      "n_games_reward: 1338542\n",
      "avg_reward_per_game: 267.71\n",
      "win_percent: 0.40\n",
      "exp.states.shape:  (76528, 13, 4, 4)\n",
      "exp.actions.shape:  (76528,)\n",
      "exp.rewards.shape:  (76528,)\n",
      "exp.states[0]:  [[[1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n",
      "exp.actions[0]:  5\n",
      "exp.rewards[0]:  -1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76528, 13, 4, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_02 = load_experience(h5py.File('prob_agent_experience_02', 'r'))\n",
    "experience_02.states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In addition, another experience data set had been generated (also 5,000 games). It was saved as 'prob_agent_experience_03'\n",
    "\n",
    "Number of games: 5000\n",
    "\n",
    "Total number of moves: 76398\n",
    "\n",
    "n_games_reward: 1321732\n",
    "\n",
    "avg_reward_per_game: 264\n",
    "\n",
    "wins/games: 0.398\n",
    "\n",
    "exp.states.shape: (76398, 13, 4, 4)\n",
    "\n",
    "exp.actions.shape: (76398,)\n",
    "\n",
    "exp.rewards.shape: (76398,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
